# Social Posts (LinkedIn + X)

## LinkedIn (single post)

**Post:**
Prompt injection still breaks production LLM apps.

I built **TrustLayer** — an API firewall for LLMs that:
- blocks prompt injection & jailbreaks
- detects agent drift over time
- provides a kill switch for incidents

Docs + examples are public. Free tier on RapidAPI.

GitHub: https://github.com/WardLink/TrustLayer--Security-Control-Plane-For-LLM-AI
RapidAPI: https://rapidapi.com/sk31898/api/trustlayer-ai-control-plane-for-safe-llms-agents

#AI #LLMSecurity #MLOps #AIOps #Cybersecurity

---

## LinkedIn (short)

Shipping LLM apps? Prompt injection is already breaking production.

TrustLayer adds a **security control plane** between your app and the model:
- prompt injection detection
- drift monitoring
- incident kill switch

Docs + free tier:
https://rapidapi.com/sk31898/api/trustlayer-ai-control-plane-for-safe-llms-agents

---

## X Thread (7 posts)

1) Prompt injection still breaks production LLM apps.
2) I built TrustLayer — an API firewall for LLMs & AI agents.
3) It blocks prompt injection + jailbreaks before the model sees them.
4) It detects agent drift when behavior silently changes.
5) It includes a kill switch for incidents.
6) Docs + examples are public:
   https://github.com/WardLink/TrustLayer--Security-Control-Plane-For-LLM-AI
7) Free tier on RapidAPI:
   https://rapidapi.com/sk31898/api/trustlayer-ai-control-plane-for-safe-llms-agents

---

## X (single post)

Prompt injection is still breaking production LLM apps.

TrustLayer = API firewall for LLMs:
- prompt injection blocking
- drift detection
- kill switch

Docs: https://github.com/WardLink/TrustLayer--Security-Control-Plane-For-LLM-AI
RapidAPI: https://rapidapi.com/sk31898/api/trustlayer-ai-control-plane-for-safe-llms-agents
